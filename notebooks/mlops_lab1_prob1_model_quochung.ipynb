{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/tranquochung/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/tranquochung/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: lightgbm in /home/tranquochung/.local/lib/python3.10/site-packages (3.3.5)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in /home/tranquochung/.local/lib/python3.10/site-packages (from lightgbm) (1.22.4)\n",
      "Requirement already satisfied: scipy in /home/tranquochung/.local/lib/python3.10/site-packages (from lightgbm) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/tranquochung/.local/lib/python3.10/site-packages (from lightgbm) (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/tranquochung/.local/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tranquochung/.local/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/tranquochung/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/tranquochung/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/tranquochung/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/tranquochung/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tabulate in /home/tranquochung/.local/lib/python3.10/site-packages (0.9.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/tranquochung/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -andas (/home/tranquochung/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%file requirements.txt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "#IMPORT THE LIBRARIES....\n",
    "import numpy as np # linear algebra....\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)....\n",
    "from matplotlib import pyplot as plt #Visualization of the data....\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from plotly import tools\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "\n",
    "# To be used for missing value imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To help with model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# To get different metric scores, and split data\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    # confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    RocCurveDisplay,\n",
    "    # plot_roc_curve,\n",
    ")\n",
    "\n",
    "# To be used for data scaling and encoding\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    "    RobustScaler,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To be used for tuning the model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# To be used for creating pipelines and personalizing them\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "# To oversample and undersample data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# To define maximum number of columns to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# To supress scientific notations for a dataframe\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "# set the background for the graphs\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# For pandas profiling\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# Printing style\n",
    "!pip install tabulate\n",
    "from tabulate import tabulate\n",
    "\n",
    "# To supress warnings\n",
    "import warnings\n",
    "\n",
    "# date time\n",
    "from datetime import datetime\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PHASE1_FOLDER = \"../data/phase-1\"\n",
    "DATA_PROB1_FOLDER = os.path.join(DATA_PHASE1_FOLDER, \"prob-1\")\n",
    "DATA_PROB2_FOLDER = os.path.join(DATA_PHASE1_FOLDER, \"prob-2\")\n",
    "\n",
    "PARQUET_PROB1 = os.path.join(DATA_PROB1_FOLDER, \"raw_train.parquet\")\n",
    "PARQUET_PROB2 = os.path.join(DATA_PROB2_FOLDER, \"raw_train.parquet\")\n",
    "\n",
    "CSV_PROB1     = os.path.join(DATA_PROB1_FOLDER, \"prob1.csv\")\n",
    "CSV_PROB2     = os.path.join(DATA_PROB2_FOLDER, \"prob2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/phase-1/prob-1/raw_train.parquet'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARQUET_PROB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "df1 = pq.read_table(source=PARQUET_PROB1).to_pandas()\n",
    "df2 = pq.read_table(source=PARQUET_PROB2).to_pandas()\n",
    "\n",
    "df1.to_csv(CSV_PROB1, index=False)\n",
    "df1.to_csv(CSV_PROB2, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note book is focus on modeling the problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read prob1 data \n",
    "df1 = pd.read_csv(CSV_PROB1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>label</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Site engineer</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>8.600</td>\n",
       "      <td>48230</td>\n",
       "      <td>40.213</td>\n",
       "      <td>-85.204</td>\n",
       "      <td>47583</td>\n",
       "      <td>42.508</td>\n",
       "      <td>-83.168</td>\n",
       "      <td>65.596</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.018</td>\n",
       "      <td>1.029</td>\n",
       "      <td>58.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Site engineer</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>316.840</td>\n",
       "      <td>48230</td>\n",
       "      <td>44.379</td>\n",
       "      <td>-82.860</td>\n",
       "      <td>47583</td>\n",
       "      <td>42.662</td>\n",
       "      <td>-81.967</td>\n",
       "      <td>64.729</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.769</td>\n",
       "      <td>1.106</td>\n",
       "      <td>64.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Site engineer</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>294.890</td>\n",
       "      <td>48230</td>\n",
       "      <td>42.951</td>\n",
       "      <td>-84.936</td>\n",
       "      <td>47583</td>\n",
       "      <td>42.580</td>\n",
       "      <td>-82.409</td>\n",
       "      <td>65.435</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.996</td>\n",
       "      <td>0.900</td>\n",
       "      <td>57.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Site engineer</td>\n",
       "      <td>shopping_net</td>\n",
       "      <td>831.080</td>\n",
       "      <td>48230</td>\n",
       "      <td>39.372</td>\n",
       "      <td>-84.894</td>\n",
       "      <td>47583</td>\n",
       "      <td>41.949</td>\n",
       "      <td>-83.920</td>\n",
       "      <td>64.990</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.768</td>\n",
       "      <td>1.063</td>\n",
       "      <td>62.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Site engineer</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>1063.840</td>\n",
       "      <td>48230</td>\n",
       "      <td>41.227</td>\n",
       "      <td>-83.228</td>\n",
       "      <td>47583</td>\n",
       "      <td>41.545</td>\n",
       "      <td>-82.123</td>\n",
       "      <td>65.316</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.816</td>\n",
       "      <td>0.722</td>\n",
       "      <td>63.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature1        feature2  feature3  feature4  feature5  feature6  \\\n",
       "0  Site engineer     grocery_pos     8.600     48230    40.213   -85.204   \n",
       "1  Site engineer   gas_transport   316.840     48230    44.379   -82.860   \n",
       "2  Site engineer     grocery_pos   294.890     48230    42.951   -84.936   \n",
       "3  Site engineer    shopping_net   831.080     48230    39.372   -84.894   \n",
       "4  Site engineer  health_fitness  1063.840     48230    41.227   -83.228   \n",
       "\n",
       "   feature7  feature8  feature9  feature10  feature11  feature12  feature13  \\\n",
       "0     47583    42.508   -83.168     65.596          3          5          1   \n",
       "1     47583    42.662   -81.967     64.729          6          5          1   \n",
       "2     47583    42.580   -82.409     65.435          3          5          1   \n",
       "3     47583    41.949   -83.920     64.990         23          6          1   \n",
       "4     47583    41.545   -82.123     65.316         23          6          1   \n",
       "\n",
       "   label  feature14  feature15  feature16  \n",
       "0      1      8.018      1.029     58.911  \n",
       "1      1     11.769      1.106     64.431  \n",
       "2      1      7.996      0.900     57.545  \n",
       "3      1      8.768      1.063     62.681  \n",
       "4      1      8.816      0.722     63.084  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134201, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: \n",
      "\n",
      " (80520, 14) \n",
      "\n",
      "Validation Data Shape: \n",
      "\n",
      " (26840, 14) \n",
      "\n",
      "Testing Data Shape: \n",
      "\n",
      " (26841, 14)\n"
     ]
    }
   ],
   "source": [
    "# spliting data set into training dataset, validation dataset and testing dataset\n",
    "\n",
    "test_size = 0.2\n",
    "val_size  = 0.25\n",
    "seed      = 1\n",
    "loss_func = \"logloss\"\n",
    "\n",
    "X,y = df1.drop(columns=[\"label\", \"feature1\", \"feature2\"]), df1[\"label\"]\n",
    "\n",
    "# then we split the temporary set into train and validation\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=seed, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# then we split the temporary set into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=val_size, random_state=seed, stratify=y_temp\n",
    ")\n",
    "print(\n",
    "    \"Training data shape: \\n\\n\",\n",
    "    X_train.shape,\n",
    "    \"\\n\\nValidation Data Shape: \\n\\n\",\n",
    "    X_val.shape,\n",
    "    \"\\n\\nTesting Data Shape: \\n\\n\",\n",
    "    X_test.shape,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      " 0   0.937\n",
      "1   0.063\n",
      "Name: label, dtype: float64\n",
      "\n",
      "\n",
      "Validation: \n",
      " 0   0.937\n",
      "1   0.063\n",
      "Name: label, dtype: float64\n",
      "\n",
      "\n",
      "Test: \n",
      " 0   0.937\n",
      "1   0.063\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training: \\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\n\\nValidation: \\n\", y_val.value_counts(normalize=True))\n",
    "print(\"\\n\\nTest: \\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing steps:\n",
    "\n",
    "- Drop feature 1 and feature 2 as it's job and job sector related, which is not the cause for fraud transaction based on job titles. (bias factors)\n",
    "\n",
    "- Data Split into Dependent and Target sets\n",
    "\n",
    "- Data Split to Train, Test and Validation sets Standardize feature names\n",
    "\n",
    "- Missing Value/Incorrect Value treatment\n",
    "\n",
    "- Encoding Scaling/Outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% file data_preprocessing.py\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "# building a func to standardize cols\n",
    "def feature_name_standardize(df : pd.DataFrame):\n",
    "    df_ = df.copy()\n",
    "    df_.columns = [i.replace(\" \", \"_\").lower() for i in df_.columns]\n",
    "    return df_\n",
    "\n",
    "# Building a func to drop features\n",
    "def drop_feature(df : pd.DataFrame, features: list()):\n",
    "    if (len(features) != 0):\n",
    "        df_ = df_.drop(columns=features)\n",
    "    \n",
    "    return df_\n",
    "\n",
    "# Building a func to treat incorrect value\n",
    "def mask_value(df: pd.DataFrame, feature: str = None, value_to_mask: str = None, masked_value: str = None):\n",
    "    df_ = df.copy()\n",
    "    if feature != None and value_to_mask != None:\n",
    "        if feature in df_.columns:\n",
    "            df_[feature] = df_[feature].astype('object')\n",
    "            df_.loc[df_[df_[feature] == value_to_mask].index, feature] = masked_value\n",
    "            df_[feature] = df_[feature].astype('category')\n",
    "    \n",
    "    return df_\n",
    "\n",
    "# Building a custom imputer\n",
    "def impute_category_unknown(df : pd.DataFrame, fill_value: str):\n",
    "    df_ = df.copy()\n",
    "    for col in df_.select_dtypes(include='category').columns.tolist():\n",
    "        df_[col] = df_[col].astype('object')\n",
    "        df_[col] = df_[col].fillna('Unknown')\n",
    "        df_[col] = df_[col].astype('category')\n",
    "    \n",
    "    return df_\n",
    "\n",
    "# Building a custom data preprocessing class with fit and transform methods for standardizing column names\n",
    "class FeatureNamesStandardizer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Returns dataframe with column names in lower case with underscores in place of spaces.\"\"\"\n",
    "        X_ = feature_name_standardize(X)\n",
    "        return X_\n",
    "\n",
    "# Building a custom data preprocessing class with fit and transform methods for dropping columns\n",
    "class ColumnDropper(TransformerMixin):\n",
    "    def __init__(self, features : list()):\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"given a list of columns, return a dataframe without those columns\"\"\"\n",
    "        X_ = drop_feature(X, features=self.features)\n",
    "        return X_\n",
    "    \n",
    "\n",
    "# Building a custom data preprocessing class with fit and transform methods for custom value masking\n",
    "class CustomValueMasker(TransformerMixin):\n",
    "    def __init__(self, feature: str, value_to_mask: str, masked_value: str):\n",
    "        self.feature = feature\n",
    "        self.value_to_mask = value_to_mask\n",
    "        self.masked_value = masked_value\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return a dataframe with the required feature value masked as required.\"\"\"\n",
    "        X_ = mask_value(X, self.feature, self.value_to_mask, self.masked_value)\n",
    "        return X_\n",
    "    \n",
    "    \n",
    "# Building a custom class to one-hot encode using pandas\n",
    "class PandasOneHot(TransformerMixin):\n",
    "    def __init__(self, columns: list = None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return a dataframe with the required feature value masked as required.\"\"\"\n",
    "        X_ = pd.get_dummies(X, columns = self.columns, drop_first=True)\n",
    "        return X_\n",
    "    \n",
    "# Building a custom class to fill nulls with Unknown\n",
    "class FillUnknown(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return a dataframe with the required feature value masked as required.\"\"\"\n",
    "        X_ = impute_category_unknown(X, fill_value='Unknown')\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%file data_preprocessing.py\n",
    "# To be used for creating pipelines and personalizing them\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "# Building a function to standardize columns\n",
    "\n",
    "def feature_name_standardize(df: pd.DataFrame):\n",
    "    df_ = df.copy()\n",
    "    df_.columns = [i.replace(\" \", \"_\").lower() for i in df_.columns]\n",
    "    return df_\n",
    "\n",
    "# Building a function to drop features\n",
    "\n",
    "def drop_feature(df: pd.DataFrame, features: list = []):\n",
    "    df_ = df.copy()\n",
    "    if len(features) != 0:\n",
    "        df_ = df_.drop(columns=features)\n",
    "        \n",
    "    return df_\n",
    "\n",
    "# Building a function to treat incorrect value\n",
    "\n",
    "def mask_value(df: pd.DataFrame, feature: str = None, value_to_mask: str = None, masked_value: str = None):\n",
    "    df_ = df.copy()\n",
    "    if feature != None and value_to_mask != None:\n",
    "        if feature in df_.columns:\n",
    "            df_[feature] = df_[feature].astype('object')\n",
    "            df_.loc[df_[df_[feature] == value_to_mask].index, feature] = masked_value\n",
    "            df_[feature] = df_[feature].astype('category')\n",
    "            \n",
    "    return df_\n",
    "\n",
    "# Building a custom imputer\n",
    "\n",
    "def impute_category_unknown(df: pd.DataFrame, fill_value: str):\n",
    "    df_ = df.copy()\n",
    "    for col in df_.select_dtypes(include='category').columns.tolist():\n",
    "        df_[col] = df_[col].astype('object')\n",
    "        df_[col] = df_[col].fillna('Unknown')\n",
    "        df_[col] = df_[col].astype('category')\n",
    "    return df_\n",
    "\n",
    "# Building a custom data preprocessing class with fit and transform methods for standardizing column names\n",
    "\n",
    "class FeatureNamesStandardizer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Returns dataframe with column names in lower case with underscores in place of spaces.\"\"\"\n",
    "        X_ = feature_name_standardize(X)\n",
    "        return X_\n",
    "    \n",
    "    \n",
    "# Building a custom data preprocessing class with fit and transform methods for dropping columns\n",
    "\n",
    "class ColumnDropper(TransformerMixin):\n",
    "    def __init__(self, features: list):\n",
    "        self.features = features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Given a list of columns, returns a dataframe without those columns.\"\"\"\n",
    "        X_ = drop_feature(X, features=self.features)\n",
    "        return X_\n",
    "        \n",
    "    \n",
    "\n",
    "# Building a custom data preprocessing class with fit and transform methods for custom value masking\n",
    "\n",
    "class CustomValueMasker(TransformerMixin):\n",
    "    def __init__(self, feature: str, value_to_mask: str, masked_value: str):\n",
    "        self.feature = feature\n",
    "        self.value_to_mask = value_to_mask\n",
    "        self.masked_value = masked_value\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return a dataframe with the required feature value masked as required.\"\"\"\n",
    "        X_ = mask_value(X, self.feature, self.value_to_mask, self.masked_value)\n",
    "        return X_\n",
    "    \n",
    "    \n",
    "# Building a custom class to one-hot encode using pandas\n",
    "class PandasOneHot(TransformerMixin):\n",
    "    def __init__(self, columns: list = None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return a dataframe with the required feature value masked as required.\"\"\"\n",
    "        X_ = pd.get_dummies(X, columns = self.columns, drop_first=True)\n",
    "        return X_\n",
    "    \n",
    "# Building a custom class to fill nulls with Unknown\n",
    "class FillUnknown(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"All SciKit-Learn compatible transformers and classifiers have the\n",
    "        same interface. `fit` always returns the same object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return a dataframe with the required feature value masked as required.\"\"\"\n",
    "        X_ = impute_category_unknown(X, fill_value='Unknown')\n",
    "        return X_\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "  X_train_prep = X_train.copy()\n",
    "  X_val_prep   = X_val.copy()\n",
    "  X_test_prep  = X_test.copy()\n",
    "  \n",
    "  # To Standardize feature names\n",
    "  feature_name_standardizer = FeatureNamesStandardizer()\n",
    "  \n",
    "  X_train_prep = feature_name_standardizer.fit_transform(X_train_prep)\n",
    "  X_val_prep   = feature_name_standardizer.transform(X_val_prep)\n",
    "  X_test_prep  = feature_name_standardizer.transform(X_test_prep)\n",
    "\n",
    "\n",
    "  # To impute categorical Nulls to Unknown\n",
    "  cat_columns = X_train.select_dtypes(include=\"category\").columns.tolist()\n",
    "  imputer = FillUnknown()\n",
    "\n",
    "  X_train_prep[cat_columns] = imputer.fit_transform(X_train_prep[cat_columns])\n",
    "  X_val_prep[cat_columns] = imputer.transform(X_val_prep[cat_columns])\n",
    "  X_test_prep[cat_columns] = imputer.transform(X_test_prep[cat_columns])\n",
    "\n",
    "  # To encode the data\n",
    "  one_hot = PandasOneHot()\n",
    "\n",
    "  X_train_prep = one_hot.fit_transform(X_train_prep)\n",
    "  X_val_prep = one_hot.transform(X_val_prep)\n",
    "  X_test_prep = one_hot.transform(X_test_prep)\n",
    "\n",
    "\n",
    "  # Scale the numerical columns\n",
    "  robust_scaler = RobustScaler(with_centering=False, with_scaling=True)\n",
    "  num_columns = [\n",
    "          \"feature3\",\n",
    "          \"feature4\",\n",
    "          \"feature5\",\n",
    "          \"feature6\",\n",
    "          \"feature7\",\n",
    "          \"feature8\",\n",
    "          \"feature9\",\n",
    "          \"feature10\",\n",
    "          \"feature11\",\n",
    "          \"feature12\",\n",
    "          \"feature13\",\n",
    "          \"feature14\",\n",
    "          \"feature15\",\n",
    "          \"feature16\"\n",
    "      ]\n",
    "\n",
    "  X_train_prep[num_columns] = pd.DataFrame(\n",
    "      robust_scaler.fit_transform(X_train_prep[num_columns]),\n",
    "      columns=num_columns,\n",
    "      index=X_train_prep.index,\n",
    "  )\n",
    "  X_val_prep[num_columns] = pd.DataFrame(\n",
    "      robust_scaler.transform(X_val_prep[num_columns]), columns=num_columns, index=X_val_prep.index\n",
    "  )\n",
    "  X_test_prep[num_columns] = pd.DataFrame(\n",
    "      robust_scaler.transform(X_test_prep[num_columns]),\n",
    "      columns=num_columns,\n",
    "      index=X_test_prep.index,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87583</th>\n",
       "      <td>0.721</td>\n",
       "      <td>0.422</td>\n",
       "      <td>4.671</td>\n",
       "      <td>-3.902</td>\n",
       "      <td>0.046</td>\n",
       "      <td>5.431</td>\n",
       "      <td>-4.216</td>\n",
       "      <td>1.627</td>\n",
       "      <td>1.417</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.408</td>\n",
       "      <td>1.865</td>\n",
       "      <td>10.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>0.760</td>\n",
       "      <td>1.888</td>\n",
       "      <td>4.771</td>\n",
       "      <td>-6.149</td>\n",
       "      <td>3.469</td>\n",
       "      <td>5.097</td>\n",
       "      <td>-6.761</td>\n",
       "      <td>2.481</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.797</td>\n",
       "      <td>2.942</td>\n",
       "      <td>9.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58795</th>\n",
       "      <td>0.481</td>\n",
       "      <td>0.887</td>\n",
       "      <td>5.614</td>\n",
       "      <td>-4.242</td>\n",
       "      <td>0.206</td>\n",
       "      <td>5.653</td>\n",
       "      <td>-4.503</td>\n",
       "      <td>1.776</td>\n",
       "      <td>0.167</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.104</td>\n",
       "      <td>0.948</td>\n",
       "      <td>9.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109984</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.578</td>\n",
       "      <td>4.726</td>\n",
       "      <td>-4.336</td>\n",
       "      <td>0.519</td>\n",
       "      <td>4.859</td>\n",
       "      <td>-4.542</td>\n",
       "      <td>1.928</td>\n",
       "      <td>1.417</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.504</td>\n",
       "      <td>2.321</td>\n",
       "      <td>10.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97100</th>\n",
       "      <td>0.488</td>\n",
       "      <td>0.904</td>\n",
       "      <td>5.239</td>\n",
       "      <td>-4.477</td>\n",
       "      <td>0.218</td>\n",
       "      <td>5.367</td>\n",
       "      <td>-4.679</td>\n",
       "      <td>1.339</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.200</td>\n",
       "      <td>1.340</td>\n",
       "      <td>9.715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature3  feature4  feature5  feature6  feature7  feature8  feature9  \\\n",
       "87583      0.721     0.422     4.671    -3.902     0.046     5.431    -4.216   \n",
       "5779       0.760     1.888     4.771    -6.149     3.469     5.097    -6.761   \n",
       "58795      0.481     0.887     5.614    -4.242     0.206     5.653    -4.503   \n",
       "109984     0.062     0.578     4.726    -4.336     0.519     4.859    -4.542   \n",
       "97100      0.488     0.904     5.239    -4.477     0.218     5.367    -4.679   \n",
       "\n",
       "        feature10  feature11  feature12  feature13  feature14  feature15  \\\n",
       "87583       1.627      1.417      2.000      2.000      3.408      1.865   \n",
       "5779        2.481      0.750      0.333      1.000      2.797      2.942   \n",
       "58795       1.776      0.167      2.000      1.000      4.104      0.948   \n",
       "109984      1.928      1.417      1.000      1.000      3.504      2.321   \n",
       "97100       1.339      1.750      0.333      1.000      2.200      1.340   \n",
       "\n",
       "        feature16  \n",
       "87583      10.531  \n",
       "5779        9.761  \n",
       "58795       9.644  \n",
       "109984     10.414  \n",
       "97100       9.715  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "      <td>80520.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.218</td>\n",
       "      <td>1.016</td>\n",
       "      <td>4.825</td>\n",
       "      <td>-4.755</td>\n",
       "      <td>1.274</td>\n",
       "      <td>5.066</td>\n",
       "      <td>-5.080</td>\n",
       "      <td>2.042</td>\n",
       "      <td>1.061</td>\n",
       "      <td>1.159</td>\n",
       "      <td>1.505</td>\n",
       "      <td>2.764</td>\n",
       "      <td>1.823</td>\n",
       "      <td>9.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.505</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.846</td>\n",
       "      <td>2.393</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1.537</td>\n",
       "      <td>-8.971</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.559</td>\n",
       "      <td>-9.352</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>-1.149</td>\n",
       "      <td>6.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.122</td>\n",
       "      <td>0.563</td>\n",
       "      <td>4.326</td>\n",
       "      <td>-5.119</td>\n",
       "      <td>0.072</td>\n",
       "      <td>4.572</td>\n",
       "      <td>-5.424</td>\n",
       "      <td>1.481</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.264</td>\n",
       "      <td>1.288</td>\n",
       "      <td>8.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.927</td>\n",
       "      <td>4.858</td>\n",
       "      <td>-4.513</td>\n",
       "      <td>0.267</td>\n",
       "      <td>5.109</td>\n",
       "      <td>-4.812</td>\n",
       "      <td>1.901</td>\n",
       "      <td>1.167</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.765</td>\n",
       "      <td>1.776</td>\n",
       "      <td>9.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.122</td>\n",
       "      <td>1.563</td>\n",
       "      <td>5.326</td>\n",
       "      <td>-4.119</td>\n",
       "      <td>1.072</td>\n",
       "      <td>5.572</td>\n",
       "      <td>-4.424</td>\n",
       "      <td>2.481</td>\n",
       "      <td>1.583</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.264</td>\n",
       "      <td>2.288</td>\n",
       "      <td>9.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>196.207</td>\n",
       "      <td>2.002</td>\n",
       "      <td>9.951</td>\n",
       "      <td>-3.285</td>\n",
       "      <td>12.521</td>\n",
       "      <td>9.719</td>\n",
       "      <td>-3.826</td>\n",
       "      <td>4.108</td>\n",
       "      <td>1.917</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.798</td>\n",
       "      <td>5.661</td>\n",
       "      <td>12.651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature3  feature4  feature5  feature6  feature7  feature8  feature9  \\\n",
       "count 80520.000 80520.000 80520.000 80520.000 80520.000 80520.000 80520.000   \n",
       "mean      1.218     1.016     4.825    -4.755     1.274     5.066    -5.080   \n",
       "std       2.505     0.593     0.739     0.846     2.393     0.731     0.898   \n",
       "min       0.012     0.022     1.537    -8.971     0.001     2.559    -9.352   \n",
       "25%       0.122     0.563     4.326    -5.119     0.072     4.572    -5.424   \n",
       "50%       0.600     0.927     4.858    -4.513     0.267     5.109    -4.812   \n",
       "75%       1.122     1.563     5.326    -4.119     1.072     5.572    -4.424   \n",
       "max     196.207     2.002     9.951    -3.285    12.521     9.719    -3.826   \n",
       "\n",
       "       feature10  feature11  feature12  feature13  feature14  feature15  \\\n",
       "count  80520.000  80520.000  80520.000  80520.000  80520.000  80520.000   \n",
       "mean       2.042      1.061      1.159      1.505      2.764      1.823   \n",
       "std        0.703      0.587      0.665      0.537      0.738      0.803   \n",
       "min        0.992      0.000      0.000      1.000     -0.343     -1.149   \n",
       "25%        1.481      0.583      0.667      1.000      2.264      1.288   \n",
       "50%        1.901      1.167      1.333      1.000      2.765      1.776   \n",
       "75%        2.481      1.583      1.667      2.000      3.264      2.288   \n",
       "max        4.108      1.917      2.000      3.000      5.798      5.661   \n",
       "\n",
       "       feature16  \n",
       "count  80520.000  \n",
       "mean       9.431  \n",
       "std        0.748  \n",
       "min        6.095  \n",
       "25%        8.936  \n",
       "50%        9.441  \n",
       "75%        9.936  \n",
       "max       12.651  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prep.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: \n",
      "\n",
      " (80520, 14) \n",
      "\n",
      "Validation Data Shape: \n",
      "\n",
      " (26840, 14) \n",
      "\n",
      "Testing Data Shape: \n",
      "\n",
      " (26841, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Training data shape: \\n\\n\",\n",
    "    X_train_prep.shape,\n",
    "    \"\\n\\nValidation Data Shape: \\n\\n\",\n",
    "    X_val_prep.shape,\n",
    "    \"\\n\\nTesting Data Shape: \\n\\n\",\n",
    "    X_test_prep.shape,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Fraud transaction classification challenge, with the input information, Let's start by building different models using KFold and cross_val_score and tune the best model using RandomizedSearchCV\n",
    "\n",
    "Stratified K-Folds cross-validation provides dataset indices to split data into train/validation sets. Split dataset into k consecutive folds (without shuffling by default) keeping the distribution of both classes in each fold the same as the target variable. Each fold is then used once as validation while the k - 1 remaining folds form the training set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building folowing models: \n",
    "\n",
    "- LDA\n",
    "- QDA\n",
    "- Linear regression\n",
    "- SVM \n",
    "- KNN\n",
    "- Naive Bayes\n",
    "\n",
    "\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- Ada Boosting\n",
    "- Extream Gradient Boosting\n",
    "- Decesion Tree Classification \n",
    "- Light Gradient Boosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light GBM is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithm, used for ranking, classification and many other machine learning tasks.\n",
    "\n",
    "Since it is based on decision tree algorithms, it splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise or level wise rather than leaf-wise. So when growing on the same leaf in Light GBM, the leaf-wise algorithm can reduce more loss than the level-wise algorithm and hence results in much better accuracy which can rarely be achieved by any of the existing boosting algorithms. Before is a diagrammatic representation by the makers of the Light GBM to explain the difference clearly. (Source: TowardsDataScience)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I add aditional model : LDA, QDA, LR, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model          import LogisticRegression\n",
    "from sklearn.naive_bayes           import GaussianNB\n",
    "from sklearn.neighbors             import KNeighborsClassifier\n",
    "from sklearn.svm                   import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LDA model for training\n",
      "Using QDA model for training\n",
      "Using LR model for training\n",
      "Using NB model for training\n",
      "Using KNN model for training\n",
      "Using Bagging model for training\n",
      "Using Random forest model for training\n",
      "Using GBM model for training\n",
      "Using Adaboost model for training\n",
      "Using Xgboost model for training\n",
      "Using DecisionTreeClassifier model for training\n",
      "Using Light GBM model for training\n",
      "Operation Completed\n",
      "<pandas.io.formats.style.Styler object at 0x7f0c4fa632e0>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# %%file origin_model.py\n",
    "# with original dataset\n",
    "\n",
    "def get_metrics_score(\n",
    "        model, train, test, train_y, test_y, threshold=0.5, flag=False, roc=True\n",
    "):\n",
    "    # defining an empty list to store train and test res\n",
    "\n",
    "    score_list = []\n",
    "\n",
    "    pred_train = model.predict_proba(train)[:, 1] > threshold\n",
    "    pred_test  = model.predict_proba(test)[:, 1]  > threshold\n",
    "\n",
    "    pred_train = np.round(pred_train)\n",
    "    pred_test  = np.round(pred_test)\n",
    "\n",
    "    train_acc  = accuracy_score(pred_train, train_y)\n",
    "    test_acc   = accuracy_score(pred_test, test_y)\n",
    "   \n",
    "    train_recall = recall_score(train_y, pred_train)\n",
    "    test_recall  = recall_score(test_y, pred_test)\n",
    "\n",
    "    train_precision = precision_score(train_y, pred_train)\n",
    "    test_precision  = precision_score(test_y, pred_test)\n",
    "\n",
    "    train_f1 = f1_score(train_y, pred_train)\n",
    "    test_f1  = f1_score(test_y, pred_test)\n",
    "\n",
    "    pred_train_proba = model.predict_proba(train)[:, 1]\n",
    "    pred_test_proba  = model.predict_proba(test)[:, 1]\n",
    "\n",
    "    train_roc_auc = roc_auc_score(train_y, pred_train_proba)\n",
    "    test_roc_auc  = roc_auc_score(test_y, pred_test_proba)\n",
    "    \n",
    "    score_list.extend(\n",
    "        (\n",
    "            train_acc,\n",
    "            test_acc,\n",
    "            train_recall,\n",
    "            test_recall,\n",
    "            train_precision,\n",
    "            test_precision,\n",
    "            train_f1,\n",
    "            test_f1,\n",
    "            train_roc_auc,\n",
    "            test_roc_auc,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if flag == True:\n",
    "        print(\"Accuracy on training set  : \", accuracy_score(pred_train, train_y))\n",
    "        print(\"Accuracy on test set      : \", accuracy_score(pred_test, test_y))\n",
    "        print(\"Recall on training set    : \", recall_score(train_y, pred_train))\n",
    "        print(\"Recall on test set        : \", recall_score(test_y, pred_test))\n",
    "        print(\"Precision on training set : \", precision_score(train_y, pred_train))\n",
    "        print(\"Precision on test set     : \", precision_score(test_y, pred_test))\n",
    "        print(\"F1 on training set        : \", f1_score(train_y, pred_train))\n",
    "        print(\"F1 on test set            : \", f1_score(test_y, pred_test))\n",
    "\n",
    "    if roc == True:\n",
    "        if flag == True:\n",
    "            print(\n",
    "                \"ROC-AUC Score on training set : \",\n",
    "                roc_auc_score(train_y, pred_train_proba),\n",
    "            )\n",
    "            print(\n",
    "                \"ROC-AUC Score on test set : \", roc_auc_score(test_y, pred_test_proba)\n",
    "            )\n",
    "\n",
    "    return score_list  # returning the list with train and test scores\n",
    "\n",
    "# get confusion matrix\n",
    "def make_confusion_matrix(model, test_X, y_actual, labels=[1,0]):\n",
    "    \n",
    "    y_pred = model.predict(test_X)\n",
    "    cm = metrics.confusion_matrix(y_actual, y_pred, labels=[1, 0])\n",
    "    df_cm = pd.DataFrame(\n",
    "        cm,\n",
    "        index=[i for i in [\"Actual - Attributed\", \"Actual - Exisiting\"]],\n",
    "        columns=[i for i in [\"Predicted - Atrited\", \"Predicted - Existing\"]]\n",
    "    )\n",
    "\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten() / np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    sns.heatmap(df_cm, annot=labels, fmt=\"\", cmap=\"Blues\").set(title=\"Confusion Matrix\")\n",
    "\n",
    "## STEP 2: defining empty lists to add train and test results to add to each model\n",
    "model_names     = []\n",
    "acc_train       = []\n",
    "acc_test        = []\n",
    "recall_train    = []\n",
    "recall_test     = []\n",
    "precision_train = []\n",
    "precision_test  = []\n",
    "f1_train        = []\n",
    "f1_test         = []\n",
    "roc_auc_train   = []\n",
    "roc_auc_test    = []\n",
    "cross_val_train = []\n",
    "\n",
    "\n",
    "def add_score_model(model_name, score, cv_res):\n",
    "    \"\"\"Add scores to list so that we can compare all models score together\"\"\"\n",
    "    model_names.append(model_name)\n",
    "    acc_train.append(score[0])\n",
    "    acc_test.append(score[1])\n",
    "    recall_train.append(score[2])\n",
    "    recall_test.append(score[3])\n",
    "    precision_train.append(score[4])\n",
    "    precision_test.append(score[5])\n",
    "    f1_train.append(score[6])\n",
    "    f1_test.append(score[7])\n",
    "    roc_auc_train.append(score[8])\n",
    "    roc_auc_test.append(score[9])\n",
    "    cross_val_train.append(cv_res)\n",
    "\n",
    "\n",
    "# Plotting boxplots for CV scores of all models defined above\n",
    "def make_boxplot(cv_result, model_name): \n",
    "    fig = plt.figure(figsize=(17, 7))\n",
    "\n",
    "    fig.suptitle(\"Algorithm cross_val_score Comparison\")\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    plt.boxplot(cv_result)\n",
    "    ax.set_xticklabels(model_names)\n",
    "    ax.set(\n",
    "       xlabel='MODELS',\n",
    "       ylabel='cross_val_score value',\n",
    "    )\n",
    "    return plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    models     = []\n",
    "    cv_results = []\n",
    "\n",
    "    # Appending models into the list\n",
    "    models.append((\"LDA\", LinearDiscriminantAnalysis()))\n",
    "    models.append((\"QDA\", QuadraticDiscriminantAnalysis()))\n",
    "    models.append((\"LR\", LogisticRegression(random_state=seed)))\n",
    "    models.append((\"NB\", GaussianNB()))\n",
    "    models.append((\"KNN\", KNeighborsClassifier()))\n",
    "#    models.append((\"SVM\", SVC(kernel=\"rbf\", random_state=seed)))\n",
    "\n",
    "    models.append((\"Bagging\", BaggingClassifier(random_state=seed)))\n",
    "    models.append((\"Random forest\", RandomForestClassifier(random_state=seed)))\n",
    "    models.append((\"GBM\", GradientBoostingClassifier(random_state=seed)))\n",
    "    models.append((\"Adaboost\", AdaBoostClassifier(random_state=seed)))\n",
    "    models.append((\"Xgboost\", XGBClassifier(random_state=seed, eval_metric=loss_func)))\n",
    "    models.append((\"DecisionTreeClassifier\", DecisionTreeClassifier(random_state=seed)))\n",
    "    models.append((\"Light GBM\", lgb.LGBMClassifier(random_state=seed)))\n",
    "\n",
    "    # For each model, run cross validation on 9 folds (+ 1 validation fold) with scoring for recall  \n",
    "    for name, model in models:\n",
    "        scoring = \"recall\"\n",
    "        \n",
    "        kflod = StratifiedKFold(\n",
    "            n_splits=10, shuffle=True, random_state=1\n",
    "        ) # setting number of splits equal to 10\n",
    "\n",
    "        cv_res = cross_val_score(\n",
    "            estimator=model, X=X_train, y=y_train, scoring=scoring, cv=kflod\n",
    "        )\n",
    "\n",
    "        cv_results.append(cv_res)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        model_score = get_metrics_score(model, X_train, X_val, y_train, y_val)\n",
    "        add_score_model(name, model_score, cv_res.mean())\n",
    "\n",
    "        print(f\"Using {name} model for training\")\n",
    "\n",
    "print(\"Operation Completed\")\n",
    "\n",
    "\n",
    "## STEP 4: visualize all models result to compare performances\n",
    "# comparison frame\n",
    "comparison_frame = pd.DataFrame(\n",
    "      {\n",
    "          \"Model\": model_names,\n",
    "          \"Cross_Val_Score_Train\": cross_val_train,\n",
    "          \"Train_Accuracy\": acc_train,\n",
    "          \"Test_Accuracy\": acc_test,\n",
    "          \"Train_Recall\": recall_train,\n",
    "          \"Test_Recall\": recall_test,\n",
    "          \"Train_Precision\": precision_train,\n",
    "          \"Test_Precision\": precision_test,\n",
    "          \"Train_F1\": f1_train,\n",
    "          \"Test_F1\": f1_test,\n",
    "          \"Train_ROC_AUC\": roc_auc_train,\n",
    "          \"Test_ROC_AUC\": roc_auc_test,\n",
    "      }\n",
    "  )\n",
    "\n",
    "  # Also show boxplot on models performance: \n",
    "print(make_boxplot(cv_result=cv_results, model_name=model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_540db_row0_col1, #T_540db_row0_col3, #T_540db_row0_col5, #T_540db_row0_col9, #T_540db_row0_col11, #T_540db_row1_col0, #T_540db_row5_col6, #T_540db_row5_col7, #T_540db_row5_col10, #T_540db_row6_col2, #T_540db_row6_col4, #T_540db_row6_col6, #T_540db_row6_col8, #T_540db_row6_col10 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_540db_row2_col0, #T_540db_row9_col2, #T_540db_row9_col3, #T_540db_row9_col6, #T_540db_row9_col7, #T_540db_row9_col9, #T_540db_row11_col1, #T_540db_row11_col4, #T_540db_row11_col5, #T_540db_row11_col8, #T_540db_row11_col10, #T_540db_row11_col11 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_540db\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_540db_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_540db_level0_col1\" class=\"col_heading level0 col1\" >Cross_Val_Score_Train</th>\n",
       "      <th id=\"T_540db_level0_col2\" class=\"col_heading level0 col2\" >Train_Accuracy</th>\n",
       "      <th id=\"T_540db_level0_col3\" class=\"col_heading level0 col3\" >Test_Accuracy</th>\n",
       "      <th id=\"T_540db_level0_col4\" class=\"col_heading level0 col4\" >Train_Recall</th>\n",
       "      <th id=\"T_540db_level0_col5\" class=\"col_heading level0 col5\" >Test_Recall</th>\n",
       "      <th id=\"T_540db_level0_col6\" class=\"col_heading level0 col6\" >Train_Precision</th>\n",
       "      <th id=\"T_540db_level0_col7\" class=\"col_heading level0 col7\" >Test_Precision</th>\n",
       "      <th id=\"T_540db_level0_col8\" class=\"col_heading level0 col8\" >Train_F1</th>\n",
       "      <th id=\"T_540db_level0_col9\" class=\"col_heading level0 col9\" >Test_F1</th>\n",
       "      <th id=\"T_540db_level0_col10\" class=\"col_heading level0 col10\" >Train_ROC_AUC</th>\n",
       "      <th id=\"T_540db_level0_col11\" class=\"col_heading level0 col11\" >Test_ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row0\" class=\"row_heading level0 row0\" >11</th>\n",
       "      <td id=\"T_540db_row0_col0\" class=\"data row0 col0\" >Light GBM</td>\n",
       "      <td id=\"T_540db_row0_col1\" class=\"data row0 col1\" >0.930169</td>\n",
       "      <td id=\"T_540db_row0_col2\" class=\"data row0 col2\" >0.997454</td>\n",
       "      <td id=\"T_540db_row0_col3\" class=\"data row0 col3\" >0.992846</td>\n",
       "      <td id=\"T_540db_row0_col4\" class=\"data row0 col4\" >0.974500</td>\n",
       "      <td id=\"T_540db_row0_col5\" class=\"data row0 col5\" >0.928824</td>\n",
       "      <td id=\"T_540db_row0_col6\" class=\"data row0 col6\" >0.985128</td>\n",
       "      <td id=\"T_540db_row0_col7\" class=\"data row0 col7\" >0.956970</td>\n",
       "      <td id=\"T_540db_row0_col8\" class=\"data row0 col8\" >0.979785</td>\n",
       "      <td id=\"T_540db_row0_col9\" class=\"data row0 col9\" >0.942687</td>\n",
       "      <td id=\"T_540db_row0_col10\" class=\"data row0 col10\" >0.999926</td>\n",
       "      <td id=\"T_540db_row0_col11\" class=\"data row0 col11\" >0.998113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row1\" class=\"row_heading level0 row1\" >9</th>\n",
       "      <td id=\"T_540db_row1_col0\" class=\"data row1 col0\" >Xgboost</td>\n",
       "      <td id=\"T_540db_row1_col1\" class=\"data row1 col1\" >0.923108</td>\n",
       "      <td id=\"T_540db_row1_col2\" class=\"data row1 col2\" >0.999578</td>\n",
       "      <td id=\"T_540db_row1_col3\" class=\"data row1 col3\" >0.992176</td>\n",
       "      <td id=\"T_540db_row1_col4\" class=\"data row1 col4\" >0.993723</td>\n",
       "      <td id=\"T_540db_row1_col5\" class=\"data row1 col5\" >0.922353</td>\n",
       "      <td id=\"T_540db_row1_col6\" class=\"data row1 col6\" >0.999605</td>\n",
       "      <td id=\"T_540db_row1_col7\" class=\"data row1 col7\" >0.952612</td>\n",
       "      <td id=\"T_540db_row1_col8\" class=\"data row1 col8\" >0.996656</td>\n",
       "      <td id=\"T_540db_row1_col9\" class=\"data row1 col9\" >0.937238</td>\n",
       "      <td id=\"T_540db_row1_col10\" class=\"data row1 col10\" >0.999997</td>\n",
       "      <td id=\"T_540db_row1_col11\" class=\"data row1 col11\" >0.997408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row2\" class=\"row_heading level0 row2\" >8</th>\n",
       "      <td id=\"T_540db_row2_col0\" class=\"data row2 col0\" >Adaboost</td>\n",
       "      <td id=\"T_540db_row2_col1\" class=\"data row2 col1\" >0.908985</td>\n",
       "      <td id=\"T_540db_row2_col2\" class=\"data row2 col2\" >0.990288</td>\n",
       "      <td id=\"T_540db_row2_col3\" class=\"data row2 col3\" >0.989717</td>\n",
       "      <td id=\"T_540db_row2_col4\" class=\"data row2 col4\" >0.911926</td>\n",
       "      <td id=\"T_540db_row2_col5\" class=\"data row2 col5\" >0.901765</td>\n",
       "      <td id=\"T_540db_row2_col6\" class=\"data row2 col6\" >0.933159</td>\n",
       "      <td id=\"T_540db_row2_col7\" class=\"data row2 col7\" >0.933618</td>\n",
       "      <td id=\"T_540db_row2_col8\" class=\"data row2 col8\" >0.922421</td>\n",
       "      <td id=\"T_540db_row2_col9\" class=\"data row2 col9\" >0.917415</td>\n",
       "      <td id=\"T_540db_row2_col10\" class=\"data row2 col10\" >0.998011</td>\n",
       "      <td id=\"T_540db_row2_col11\" class=\"data row2 col11\" >0.996924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row3\" class=\"row_heading level0 row3\" >7</th>\n",
       "      <td id=\"T_540db_row3_col0\" class=\"data row3 col0\" >GBM</td>\n",
       "      <td id=\"T_540db_row3_col1\" class=\"data row3 col1\" >0.907610</td>\n",
       "      <td id=\"T_540db_row3_col2\" class=\"data row3 col2\" >0.992312</td>\n",
       "      <td id=\"T_540db_row3_col3\" class=\"data row3 col3\" >0.990984</td>\n",
       "      <td id=\"T_540db_row3_col4\" class=\"data row3 col4\" >0.917222</td>\n",
       "      <td id=\"T_540db_row3_col5\" class=\"data row3 col5\" >0.903529</td>\n",
       "      <td id=\"T_540db_row3_col6\" class=\"data row3 col6\" >0.959573</td>\n",
       "      <td id=\"T_540db_row3_col7\" class=\"data row3 col7\" >0.951673</td>\n",
       "      <td id=\"T_540db_row3_col8\" class=\"data row3 col8\" >0.937920</td>\n",
       "      <td id=\"T_540db_row3_col9\" class=\"data row3 col9\" >0.926976</td>\n",
       "      <td id=\"T_540db_row3_col10\" class=\"data row3 col10\" >0.997993</td>\n",
       "      <td id=\"T_540db_row3_col11\" class=\"data row3 col11\" >0.997278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_540db_row4_col0\" class=\"data row4 col0\" >Bagging</td>\n",
       "      <td id=\"T_540db_row4_col1\" class=\"data row4 col1\" >0.888780</td>\n",
       "      <td id=\"T_540db_row4_col2\" class=\"data row4 col2\" >0.999044</td>\n",
       "      <td id=\"T_540db_row4_col3\" class=\"data row4 col3\" >0.989382</td>\n",
       "      <td id=\"T_540db_row4_col4\" class=\"data row4 col4\" >0.986858</td>\n",
       "      <td id=\"T_540db_row4_col5\" class=\"data row4 col5\" >0.881176</td>\n",
       "      <td id=\"T_540db_row4_col6\" class=\"data row4 col6\" >0.998016</td>\n",
       "      <td id=\"T_540db_row4_col7\" class=\"data row4 col7\" >0.947502</td>\n",
       "      <td id=\"T_540db_row4_col8\" class=\"data row4 col8\" >0.992406</td>\n",
       "      <td id=\"T_540db_row4_col9\" class=\"data row4 col9\" >0.913136</td>\n",
       "      <td id=\"T_540db_row4_col10\" class=\"data row4 col10\" >0.999990</td>\n",
       "      <td id=\"T_540db_row4_col11\" class=\"data row4 col11\" >0.983456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_540db_row5_col0\" class=\"data row5 col0\" >Random forest</td>\n",
       "      <td id=\"T_540db_row5_col1\" class=\"data row5 col1\" >0.887797</td>\n",
       "      <td id=\"T_540db_row5_col2\" class=\"data row5 col2\" >0.999988</td>\n",
       "      <td id=\"T_540db_row5_col3\" class=\"data row5 col3\" >0.990760</td>\n",
       "      <td id=\"T_540db_row5_col4\" class=\"data row5 col4\" >0.999804</td>\n",
       "      <td id=\"T_540db_row5_col5\" class=\"data row5 col5\" >0.884706</td>\n",
       "      <td id=\"T_540db_row5_col6\" class=\"data row5 col6\" >1.000000</td>\n",
       "      <td id=\"T_540db_row5_col7\" class=\"data row5 col7\" >0.966581</td>\n",
       "      <td id=\"T_540db_row5_col8\" class=\"data row5 col8\" >0.999902</td>\n",
       "      <td id=\"T_540db_row5_col9\" class=\"data row5 col9\" >0.923833</td>\n",
       "      <td id=\"T_540db_row5_col10\" class=\"data row5 col10\" >1.000000</td>\n",
       "      <td id=\"T_540db_row5_col11\" class=\"data row5 col11\" >0.994786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row6\" class=\"row_heading level0 row6\" >10</th>\n",
       "      <td id=\"T_540db_row6_col0\" class=\"data row6 col0\" >DecisionTreeClassifier</td>\n",
       "      <td id=\"T_540db_row6_col1\" class=\"data row6 col1\" >0.883877</td>\n",
       "      <td id=\"T_540db_row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
       "      <td id=\"T_540db_row6_col3\" class=\"data row6 col3\" >0.984091</td>\n",
       "      <td id=\"T_540db_row6_col4\" class=\"data row6 col4\" >1.000000</td>\n",
       "      <td id=\"T_540db_row6_col5\" class=\"data row6 col5\" >0.864706</td>\n",
       "      <td id=\"T_540db_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_540db_row6_col7\" class=\"data row6 col7\" >0.881824</td>\n",
       "      <td id=\"T_540db_row6_col8\" class=\"data row6 col8\" >1.000000</td>\n",
       "      <td id=\"T_540db_row6_col9\" class=\"data row6 col9\" >0.873181</td>\n",
       "      <td id=\"T_540db_row6_col10\" class=\"data row6 col10\" >1.000000</td>\n",
       "      <td id=\"T_540db_row6_col11\" class=\"data row6 col11\" >0.928435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row7\" class=\"row_heading level0 row7\" >1</th>\n",
       "      <td id=\"T_540db_row7_col0\" class=\"data row7 col0\" >QDA</td>\n",
       "      <td id=\"T_540db_row7_col1\" class=\"data row7 col1\" >0.825224</td>\n",
       "      <td id=\"T_540db_row7_col2\" class=\"data row7 col2\" >0.981123</td>\n",
       "      <td id=\"T_540db_row7_col3\" class=\"data row7 col3\" >0.980551</td>\n",
       "      <td id=\"T_540db_row7_col4\" class=\"data row7 col4\" >0.825814</td>\n",
       "      <td id=\"T_540db_row7_col5\" class=\"data row7 col5\" >0.815882</td>\n",
       "      <td id=\"T_540db_row7_col6\" class=\"data row7 col6\" >0.869475</td>\n",
       "      <td id=\"T_540db_row7_col7\" class=\"data row7 col7\" >0.869048</td>\n",
       "      <td id=\"T_540db_row7_col8\" class=\"data row7 col8\" >0.847082</td>\n",
       "      <td id=\"T_540db_row7_col9\" class=\"data row7 col9\" >0.841626</td>\n",
       "      <td id=\"T_540db_row7_col10\" class=\"data row7 col10\" >0.989587</td>\n",
       "      <td id=\"T_540db_row7_col11\" class=\"data row7 col11\" >0.988034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row8\" class=\"row_heading level0 row8\" >0</th>\n",
       "      <td id=\"T_540db_row8_col0\" class=\"data row8 col0\" >LDA</td>\n",
       "      <td id=\"T_540db_row8_col1\" class=\"data row8 col1\" >0.705176</td>\n",
       "      <td id=\"T_540db_row8_col2\" class=\"data row8 col2\" >0.975571</td>\n",
       "      <td id=\"T_540db_row8_col3\" class=\"data row8 col3\" >0.976490</td>\n",
       "      <td id=\"T_540db_row8_col4\" class=\"data row8 col4\" >0.705963</td>\n",
       "      <td id=\"T_540db_row8_col5\" class=\"data row8 col5\" >0.714706</td>\n",
       "      <td id=\"T_540db_row8_col6\" class=\"data row8 col6\" >0.884927</td>\n",
       "      <td id=\"T_540db_row8_col7\" class=\"data row8 col7\" >0.892726</td>\n",
       "      <td id=\"T_540db_row8_col8\" class=\"data row8 col8\" >0.785379</td>\n",
       "      <td id=\"T_540db_row8_col9\" class=\"data row8 col9\" >0.793858</td>\n",
       "      <td id=\"T_540db_row8_col10\" class=\"data row8 col10\" >0.986170</td>\n",
       "      <td id=\"T_540db_row8_col11\" class=\"data row8 col11\" >0.985440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row9\" class=\"row_heading level0 row9\" >3</th>\n",
       "      <td id=\"T_540db_row9_col0\" class=\"data row9 col0\" >NB</td>\n",
       "      <td id=\"T_540db_row9_col1\" class=\"data row9 col1\" >0.494120</td>\n",
       "      <td id=\"T_540db_row9_col2\" class=\"data row9 col2\" >0.957650</td>\n",
       "      <td id=\"T_540db_row9_col3\" class=\"data row9 col3\" >0.958458</td>\n",
       "      <td id=\"T_540db_row9_col4\" class=\"data row9 col4\" >0.492938</td>\n",
       "      <td id=\"T_540db_row9_col5\" class=\"data row9 col5\" >0.512941</td>\n",
       "      <td id=\"T_540db_row9_col6\" class=\"data row9 col6\" >0.752846</td>\n",
       "      <td id=\"T_540db_row9_col7\" class=\"data row9 col7\" >0.752373</td>\n",
       "      <td id=\"T_540db_row9_col8\" class=\"data row9 col8\" >0.595780</td>\n",
       "      <td id=\"T_540db_row9_col9\" class=\"data row9 col9\" >0.610003</td>\n",
       "      <td id=\"T_540db_row9_col10\" class=\"data row9 col10\" >0.895781</td>\n",
       "      <td id=\"T_540db_row9_col11\" class=\"data row9 col11\" >0.888420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row10\" class=\"row_heading level0 row10\" >4</th>\n",
       "      <td id=\"T_540db_row10_col0\" class=\"data row10 col0\" >KNN</td>\n",
       "      <td id=\"T_540db_row10_col1\" class=\"data row10 col1\" >0.486667</td>\n",
       "      <td id=\"T_540db_row10_col2\" class=\"data row10 col2\" >0.969250</td>\n",
       "      <td id=\"T_540db_row10_col3\" class=\"data row10 col3\" >0.959799</td>\n",
       "      <td id=\"T_540db_row10_col4\" class=\"data row10 col4\" >0.630051</td>\n",
       "      <td id=\"T_540db_row10_col5\" class=\"data row10 col5\" >0.507647</td>\n",
       "      <td id=\"T_540db_row10_col6\" class=\"data row10 col6\" >0.844819</td>\n",
       "      <td id=\"T_540db_row10_col7\" class=\"data row10 col7\" >0.780995</td>\n",
       "      <td id=\"T_540db_row10_col8\" class=\"data row10 col8\" >0.721798</td>\n",
       "      <td id=\"T_540db_row10_col9\" class=\"data row10 col9\" >0.615330</td>\n",
       "      <td id=\"T_540db_row10_col10\" class=\"data row10 col10\" >0.989907</td>\n",
       "      <td id=\"T_540db_row10_col11\" class=\"data row10 col11\" >0.887359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_540db_level0_row11\" class=\"row_heading level0 row11\" >2</th>\n",
       "      <td id=\"T_540db_row11_col0\" class=\"data row11 col0\" >LR</td>\n",
       "      <td id=\"T_540db_row11_col1\" class=\"data row11 col1\" >0.466267</td>\n",
       "      <td id=\"T_540db_row11_col2\" class=\"data row11 col2\" >0.960532</td>\n",
       "      <td id=\"T_540db_row11_col3\" class=\"data row11 col3\" >0.961736</td>\n",
       "      <td id=\"T_540db_row11_col4\" class=\"data row11 col4\" >0.458219</td>\n",
       "      <td id=\"T_540db_row11_col5\" class=\"data row11 col5\" >0.474118</td>\n",
       "      <td id=\"T_540db_row11_col6\" class=\"data row11 col6\" >0.848837</td>\n",
       "      <td id=\"T_540db_row11_col7\" class=\"data row11 col7\" >0.858360</td>\n",
       "      <td id=\"T_540db_row11_col8\" class=\"data row11 col8\" >0.595159</td>\n",
       "      <td id=\"T_540db_row11_col9\" class=\"data row11 col9\" >0.610837</td>\n",
       "      <td id=\"T_540db_row11_col10\" class=\"data row11 col10\" >0.891261</td>\n",
       "      <td id=\"T_540db_row11_col11\" class=\"data row11 col11\" >0.884036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0c4f8f6ef0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_frame.sort_values(\n",
    "    by = [\"Cross_Val_Score_Train\", \"Test_Recall\"], ascending=False\n",
    ").style.highlight_max(color=\"green\", axis=0).highlight_min(color=\"red\", axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best model respect to cross validation score and test recall is light GBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark\n",
    "\n",
    "We can see that we have the pretty good performance in training dataset and val dataset, because of imbalanced dataset issue\n",
    "Most machine learning algorithms work best when the number of samples in each class is about equal. This is because most algorithms are designed to maximize accuracy and reduce errors.\n",
    "\n",
    "However, if the dataframe has imbalanced classes, then In such cases, we will get a pretty high accuracy just by predicting the majority class, but you fail to capture the minority class, which is most often the point of creating the model in the first place. "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Techniques to Solve Class Imbalance\n",
    "\n",
    "One of the widely adopted class imbalance techniques for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and/or adding more examples from the minority class (over-sampling).\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning dataset class 0  75422\n",
      "traning dataset class 1  5098\n"
     ]
    }
   ],
   "source": [
    "print(f\"traning dataset class 0  {y_train[y_train == 0].shape[0]}\")\n",
    "print(f\"traning dataset class 1  {y_train[y_train == 1].shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling_data():\n",
    "    return SMOTE(\n",
    "        sampling_strategy=\"minority\", k_neighbors=10, random_state=seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before UpSampling, counts of label 'Yes-fraud': 5098\n",
      "Before UpSampling, counts of label 'No-nofraud': 75422 \n",
      "\n",
      "After UpSampling, counts of label 'Yes-fraud': 75422\n",
      "After UpSampling, counts of label 'No-nofraud': 75422 \n",
      "\n",
      "After UpSampling, the shape of train_X: (150844, 14)\n",
      "After UpSampling, the shape of train_y: (150844,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_over, y_train_over = oversampling_data().fit_resample(X_train, y_train)\n",
    "print(\"Before UpSampling, counts of label 'Yes-fraud': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before UpSampling, counts of label 'No-nofraud': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "print(\"After UpSampling, counts of label 'Yes-fraud': {}\".format(sum(y_train_over == 1)))\n",
    "print(\"After UpSampling, counts of label 'No-nofraud': {} \\n\".format(sum(y_train_over == 0)))\n",
    "\n",
    "\n",
    "print(\"After UpSampling, the shape of train_X: {}\".format(X_train_over.shape))\n",
    "print(\"After UpSampling, the shape of train_y: {} \\n\".format(y_train_over.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed!\n"
     ]
    }
   ],
   "source": [
    "# %%file oversample_model.py\n",
    "# import model\n",
    "# from model import comparison_frame, make_boxplot, add_score_model\n",
    "\n",
    "def oversampling_data():\n",
    "  sm = SMOTE(\n",
    "      sampling_strategy=\"minority\", k_neighbors=10, random_state=seed\n",
    "  )  # Synthetic Minority Over Sampling Technique\n",
    "  return sm\n",
    "\n",
    "### STEP 3: model build and performance comparision with oversampling data: \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  X_train_over, y_train_over = oversampling_data().fit_resample(X_train, y_train)\n",
    "  models_over = []\n",
    "\n",
    "  # Appending models into the list\n",
    "\n",
    "  models_over.append((\"Bagging UpSampling\", BaggingClassifier(random_state=seed)))\n",
    "  models_over.append(\n",
    "      (\"Random forest UpSampling\", RandomForestClassifier(random_state=seed))\n",
    "  )\n",
    "  models_over.append((\"GBM UpSampling\", GradientBoostingClassifier(random_state=seed)))\n",
    "  models_over.append((\"Adaboost UpSampling\", AdaBoostClassifier(random_state=seed)))\n",
    "  models_over.append(\n",
    "      (\"Xgboost UpSampling\", XGBClassifier(random_state=seed, eval_metric=loss_func))\n",
    "  )\n",
    "  models_over.append((\"dtree UpSampling\", DecisionTreeClassifier(random_state=seed)))\n",
    "  models_over.append((\"Light GBM UpSampling\", lgb.LGBMClassifier(random_state=seed)))\n",
    "\n",
    "  for name, model in models_over:\n",
    "      scoring = \"recall\"\n",
    "      kfold = StratifiedKFold(\n",
    "          n_splits=10, shuffle=True, random_state=1\n",
    "      )  # Setting number of splits equal to 10\n",
    "\n",
    "      cv_result_over = cross_val_score(\n",
    "          estimator=model, X=X_train_over, y=y_train_over, scoring=scoring, cv=kfold\n",
    "      )\n",
    "      cv_results.append(cv_result_over)\n",
    "\n",
    "      model.fit(X_train_over, y_train_over)\n",
    "      model_score_over = get_metrics_score(\n",
    "          model, X_train_over, X_val, y_train_over, y_val\n",
    "      )\n",
    "      add_score_model(name, model_score_over, cv_result_over.mean())\n",
    "\n",
    "  print(\"Operation Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c4ece_row0_col5, #T_c4ece_row3_col1, #T_c4ece_row4_col2, #T_c4ece_row4_col4, #T_c4ece_row4_col6, #T_c4ece_row4_col8, #T_c4ece_row4_col10, #T_c4ece_row5_col3, #T_c4ece_row5_col9, #T_c4ece_row5_col11, #T_c4ece_row8_col0, #T_c4ece_row8_col2, #T_c4ece_row8_col4, #T_c4ece_row8_col6, #T_c4ece_row8_col8, #T_c4ece_row8_col10, #T_c4ece_row11_col6, #T_c4ece_row11_col7, #T_c4ece_row11_col10, #T_c4ece_row13_col2, #T_c4ece_row13_col4, #T_c4ece_row13_col6, #T_c4ece_row13_col8, #T_c4ece_row13_col10 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_c4ece_row8_col7, #T_c4ece_row10_col0, #T_c4ece_row16_col2, #T_c4ece_row16_col3, #T_c4ece_row16_col6, #T_c4ece_row16_col9, #T_c4ece_row18_col1, #T_c4ece_row18_col4, #T_c4ece_row18_col5, #T_c4ece_row18_col8, #T_c4ece_row18_col10, #T_c4ece_row18_col11 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c4ece\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c4ece_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c4ece_level0_col1\" class=\"col_heading level0 col1\" >Cross_Val_Score_Train</th>\n",
       "      <th id=\"T_c4ece_level0_col2\" class=\"col_heading level0 col2\" >Train_Accuracy</th>\n",
       "      <th id=\"T_c4ece_level0_col3\" class=\"col_heading level0 col3\" >Test_Accuracy</th>\n",
       "      <th id=\"T_c4ece_level0_col4\" class=\"col_heading level0 col4\" >Train_Recall</th>\n",
       "      <th id=\"T_c4ece_level0_col5\" class=\"col_heading level0 col5\" >Test_Recall</th>\n",
       "      <th id=\"T_c4ece_level0_col6\" class=\"col_heading level0 col6\" >Train_Precision</th>\n",
       "      <th id=\"T_c4ece_level0_col7\" class=\"col_heading level0 col7\" >Test_Precision</th>\n",
       "      <th id=\"T_c4ece_level0_col8\" class=\"col_heading level0 col8\" >Train_F1</th>\n",
       "      <th id=\"T_c4ece_level0_col9\" class=\"col_heading level0 col9\" >Test_F1</th>\n",
       "      <th id=\"T_c4ece_level0_col10\" class=\"col_heading level0 col10\" >Train_ROC_AUC</th>\n",
       "      <th id=\"T_c4ece_level0_col11\" class=\"col_heading level0 col11\" >Test_ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row0\" class=\"row_heading level0 row0\" >14</th>\n",
       "      <td id=\"T_c4ece_row0_col0\" class=\"data row0 col0\" >GBM UpSampling</td>\n",
       "      <td id=\"T_c4ece_row0_col1\" class=\"data row0 col1\" >0.975763</td>\n",
       "      <td id=\"T_c4ece_row0_col2\" class=\"data row0 col2\" >0.976141</td>\n",
       "      <td id=\"T_c4ece_row0_col3\" class=\"data row0 col3\" >0.973510</td>\n",
       "      <td id=\"T_c4ece_row0_col4\" class=\"data row0 col4\" >0.976612</td>\n",
       "      <td id=\"T_c4ece_row0_col5\" class=\"data row0 col5\" >0.955294</td>\n",
       "      <td id=\"T_c4ece_row0_col6\" class=\"data row0 col6\" >0.975693</td>\n",
       "      <td id=\"T_c4ece_row0_col7\" class=\"data row0 col7\" >0.718902</td>\n",
       "      <td id=\"T_c4ece_row0_col8\" class=\"data row0 col8\" >0.976152</td>\n",
       "      <td id=\"T_c4ece_row0_col9\" class=\"data row0 col9\" >0.820409</td>\n",
       "      <td id=\"T_c4ece_row0_col10\" class=\"data row0 col10\" >0.997362</td>\n",
       "      <td id=\"T_c4ece_row0_col11\" class=\"data row0 col11\" >0.995201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row1\" class=\"row_heading level0 row1\" >18</th>\n",
       "      <td id=\"T_c4ece_row1_col0\" class=\"data row1 col0\" >Light GBM UpSampling</td>\n",
       "      <td id=\"T_c4ece_row1_col1\" class=\"data row1 col1\" >0.984328</td>\n",
       "      <td id=\"T_c4ece_row1_col2\" class=\"data row1 col2\" >0.985800</td>\n",
       "      <td id=\"T_c4ece_row1_col3\" class=\"data row1 col3\" >0.980328</td>\n",
       "      <td id=\"T_c4ece_row1_col4\" class=\"data row1 col4\" >0.987152</td>\n",
       "      <td id=\"T_c4ece_row1_col5\" class=\"data row1 col5\" >0.953529</td>\n",
       "      <td id=\"T_c4ece_row1_col6\" class=\"data row1 col6\" >0.984489</td>\n",
       "      <td id=\"T_c4ece_row1_col7\" class=\"data row1 col7\" >0.783092</td>\n",
       "      <td id=\"T_c4ece_row1_col8\" class=\"data row1 col8\" >0.985819</td>\n",
       "      <td id=\"T_c4ece_row1_col9\" class=\"data row1 col9\" >0.859947</td>\n",
       "      <td id=\"T_c4ece_row1_col10\" class=\"data row1 col10\" >0.999204</td>\n",
       "      <td id=\"T_c4ece_row1_col11\" class=\"data row1 col11\" >0.995319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row2\" class=\"row_heading level0 row2\" >15</th>\n",
       "      <td id=\"T_c4ece_row2_col0\" class=\"data row2 col0\" >Adaboost UpSampling</td>\n",
       "      <td id=\"T_c4ece_row2_col1\" class=\"data row2 col1\" >0.973244</td>\n",
       "      <td id=\"T_c4ece_row2_col2\" class=\"data row2 col2\" >0.973158</td>\n",
       "      <td id=\"T_c4ece_row2_col3\" class=\"data row2 col3\" >0.972876</td>\n",
       "      <td id=\"T_c4ece_row2_col4\" class=\"data row2 col4\" >0.973032</td>\n",
       "      <td id=\"T_c4ece_row2_col5\" class=\"data row2 col5\" >0.951176</td>\n",
       "      <td id=\"T_c4ece_row2_col6\" class=\"data row2 col6\" >0.973277</td>\n",
       "      <td id=\"T_c4ece_row2_col7\" class=\"data row2 col7\" >0.714854</td>\n",
       "      <td id=\"T_c4ece_row2_col8\" class=\"data row2 col8\" >0.973154</td>\n",
       "      <td id=\"T_c4ece_row2_col9\" class=\"data row2 col9\" >0.816254</td>\n",
       "      <td id=\"T_c4ece_row2_col10\" class=\"data row2 col10\" >0.996991</td>\n",
       "      <td id=\"T_c4ece_row2_col11\" class=\"data row2 col11\" >0.993403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row3\" class=\"row_heading level0 row3\" >16</th>\n",
       "      <td id=\"T_c4ece_row3_col0\" class=\"data row3 col0\" >Xgboost UpSampling</td>\n",
       "      <td id=\"T_c4ece_row3_col1\" class=\"data row3 col1\" >0.990268</td>\n",
       "      <td id=\"T_c4ece_row3_col2\" class=\"data row3 col2\" >0.995346</td>\n",
       "      <td id=\"T_c4ece_row3_col3\" class=\"data row3 col3\" >0.983271</td>\n",
       "      <td id=\"T_c4ece_row3_col4\" class=\"data row3 col4\" >0.996566</td>\n",
       "      <td id=\"T_c4ece_row3_col5\" class=\"data row3 col5\" >0.941176</td>\n",
       "      <td id=\"T_c4ece_row3_col6\" class=\"data row3 col6\" >0.994141</td>\n",
       "      <td id=\"T_c4ece_row3_col7\" class=\"data row3 col7\" >0.820934</td>\n",
       "      <td id=\"T_c4ece_row3_col8\" class=\"data row3 col8\" >0.995352</td>\n",
       "      <td id=\"T_c4ece_row3_col9\" class=\"data row3 col9\" >0.876953</td>\n",
       "      <td id=\"T_c4ece_row3_col10\" class=\"data row3 col10\" >0.999893</td>\n",
       "      <td id=\"T_c4ece_row3_col11\" class=\"data row3 col11\" >0.994197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row4\" class=\"row_heading level0 row4\" >13</th>\n",
       "      <td id=\"T_c4ece_row4_col0\" class=\"data row4 col0\" >Random forest UpSampling</td>\n",
       "      <td id=\"T_c4ece_row4_col1\" class=\"data row4 col1\" >0.989976</td>\n",
       "      <td id=\"T_c4ece_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row4_col3\" class=\"data row4 col3\" >0.980700</td>\n",
       "      <td id=\"T_c4ece_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row4_col5\" class=\"data row4 col5\" >0.936471</td>\n",
       "      <td id=\"T_c4ece_row4_col6\" class=\"data row4 col6\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row4_col7\" class=\"data row4 col7\" >0.795205</td>\n",
       "      <td id=\"T_c4ece_row4_col8\" class=\"data row4 col8\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row4_col9\" class=\"data row4 col9\" >0.860076</td>\n",
       "      <td id=\"T_c4ece_row4_col10\" class=\"data row4 col10\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row4_col11\" class=\"data row4 col11\" >0.994260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row5\" class=\"row_heading level0 row5\" >11</th>\n",
       "      <td id=\"T_c4ece_row5_col0\" class=\"data row5 col0\" >Light GBM</td>\n",
       "      <td id=\"T_c4ece_row5_col1\" class=\"data row5 col1\" >0.930169</td>\n",
       "      <td id=\"T_c4ece_row5_col2\" class=\"data row5 col2\" >0.997454</td>\n",
       "      <td id=\"T_c4ece_row5_col3\" class=\"data row5 col3\" >0.992846</td>\n",
       "      <td id=\"T_c4ece_row5_col4\" class=\"data row5 col4\" >0.974500</td>\n",
       "      <td id=\"T_c4ece_row5_col5\" class=\"data row5 col5\" >0.928824</td>\n",
       "      <td id=\"T_c4ece_row5_col6\" class=\"data row5 col6\" >0.985128</td>\n",
       "      <td id=\"T_c4ece_row5_col7\" class=\"data row5 col7\" >0.956970</td>\n",
       "      <td id=\"T_c4ece_row5_col8\" class=\"data row5 col8\" >0.979785</td>\n",
       "      <td id=\"T_c4ece_row5_col9\" class=\"data row5 col9\" >0.942687</td>\n",
       "      <td id=\"T_c4ece_row5_col10\" class=\"data row5 col10\" >0.999926</td>\n",
       "      <td id=\"T_c4ece_row5_col11\" class=\"data row5 col11\" >0.998113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row6\" class=\"row_heading level0 row6\" >9</th>\n",
       "      <td id=\"T_c4ece_row6_col0\" class=\"data row6 col0\" >Xgboost</td>\n",
       "      <td id=\"T_c4ece_row6_col1\" class=\"data row6 col1\" >0.923108</td>\n",
       "      <td id=\"T_c4ece_row6_col2\" class=\"data row6 col2\" >0.999578</td>\n",
       "      <td id=\"T_c4ece_row6_col3\" class=\"data row6 col3\" >0.992176</td>\n",
       "      <td id=\"T_c4ece_row6_col4\" class=\"data row6 col4\" >0.993723</td>\n",
       "      <td id=\"T_c4ece_row6_col5\" class=\"data row6 col5\" >0.922353</td>\n",
       "      <td id=\"T_c4ece_row6_col6\" class=\"data row6 col6\" >0.999605</td>\n",
       "      <td id=\"T_c4ece_row6_col7\" class=\"data row6 col7\" >0.952612</td>\n",
       "      <td id=\"T_c4ece_row6_col8\" class=\"data row6 col8\" >0.996656</td>\n",
       "      <td id=\"T_c4ece_row6_col9\" class=\"data row6 col9\" >0.937238</td>\n",
       "      <td id=\"T_c4ece_row6_col10\" class=\"data row6 col10\" >0.999997</td>\n",
       "      <td id=\"T_c4ece_row6_col11\" class=\"data row6 col11\" >0.997408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row7\" class=\"row_heading level0 row7\" >12</th>\n",
       "      <td id=\"T_c4ece_row7_col0\" class=\"data row7 col0\" >Bagging UpSampling</td>\n",
       "      <td id=\"T_c4ece_row7_col1\" class=\"data row7 col1\" >0.981756</td>\n",
       "      <td id=\"T_c4ece_row7_col2\" class=\"data row7 col2\" >0.998893</td>\n",
       "      <td id=\"T_c4ece_row7_col3\" class=\"data row7 col3\" >0.977422</td>\n",
       "      <td id=\"T_c4ece_row7_col4\" class=\"data row7 col4\" >0.998581</td>\n",
       "      <td id=\"T_c4ece_row7_col5\" class=\"data row7 col5\" >0.917647</td>\n",
       "      <td id=\"T_c4ece_row7_col6\" class=\"data row7 col6\" >0.999204</td>\n",
       "      <td id=\"T_c4ece_row7_col7\" class=\"data row7 col7\" >0.769990</td>\n",
       "      <td id=\"T_c4ece_row7_col8\" class=\"data row7 col8\" >0.998893</td>\n",
       "      <td id=\"T_c4ece_row7_col9\" class=\"data row7 col9\" >0.837359</td>\n",
       "      <td id=\"T_c4ece_row7_col10\" class=\"data row7 col10\" >0.999994</td>\n",
       "      <td id=\"T_c4ece_row7_col11\" class=\"data row7 col11\" >0.982595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row8\" class=\"row_heading level0 row8\" >17</th>\n",
       "      <td id=\"T_c4ece_row8_col0\" class=\"data row8 col0\" >dtree UpSampling</td>\n",
       "      <td id=\"T_c4ece_row8_col1\" class=\"data row8 col1\" >0.974835</td>\n",
       "      <td id=\"T_c4ece_row8_col2\" class=\"data row8 col2\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row8_col3\" class=\"data row8 col3\" >0.965611</td>\n",
       "      <td id=\"T_c4ece_row8_col4\" class=\"data row8 col4\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row8_col5\" class=\"data row8 col5\" >0.908824</td>\n",
       "      <td id=\"T_c4ece_row8_col6\" class=\"data row8 col6\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row8_col7\" class=\"data row8 col7\" >0.667964</td>\n",
       "      <td id=\"T_c4ece_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row8_col9\" class=\"data row8 col9\" >0.769998</td>\n",
       "      <td id=\"T_c4ece_row8_col10\" class=\"data row8 col10\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row8_col11\" class=\"data row8 col11\" >0.939137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row9\" class=\"row_heading level0 row9\" >7</th>\n",
       "      <td id=\"T_c4ece_row9_col0\" class=\"data row9 col0\" >GBM</td>\n",
       "      <td id=\"T_c4ece_row9_col1\" class=\"data row9 col1\" >0.907610</td>\n",
       "      <td id=\"T_c4ece_row9_col2\" class=\"data row9 col2\" >0.992312</td>\n",
       "      <td id=\"T_c4ece_row9_col3\" class=\"data row9 col3\" >0.990984</td>\n",
       "      <td id=\"T_c4ece_row9_col4\" class=\"data row9 col4\" >0.917222</td>\n",
       "      <td id=\"T_c4ece_row9_col5\" class=\"data row9 col5\" >0.903529</td>\n",
       "      <td id=\"T_c4ece_row9_col6\" class=\"data row9 col6\" >0.959573</td>\n",
       "      <td id=\"T_c4ece_row9_col7\" class=\"data row9 col7\" >0.951673</td>\n",
       "      <td id=\"T_c4ece_row9_col8\" class=\"data row9 col8\" >0.937920</td>\n",
       "      <td id=\"T_c4ece_row9_col9\" class=\"data row9 col9\" >0.926976</td>\n",
       "      <td id=\"T_c4ece_row9_col10\" class=\"data row9 col10\" >0.997993</td>\n",
       "      <td id=\"T_c4ece_row9_col11\" class=\"data row9 col11\" >0.997278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row10\" class=\"row_heading level0 row10\" >8</th>\n",
       "      <td id=\"T_c4ece_row10_col0\" class=\"data row10 col0\" >Adaboost</td>\n",
       "      <td id=\"T_c4ece_row10_col1\" class=\"data row10 col1\" >0.908985</td>\n",
       "      <td id=\"T_c4ece_row10_col2\" class=\"data row10 col2\" >0.990288</td>\n",
       "      <td id=\"T_c4ece_row10_col3\" class=\"data row10 col3\" >0.989717</td>\n",
       "      <td id=\"T_c4ece_row10_col4\" class=\"data row10 col4\" >0.911926</td>\n",
       "      <td id=\"T_c4ece_row10_col5\" class=\"data row10 col5\" >0.901765</td>\n",
       "      <td id=\"T_c4ece_row10_col6\" class=\"data row10 col6\" >0.933159</td>\n",
       "      <td id=\"T_c4ece_row10_col7\" class=\"data row10 col7\" >0.933618</td>\n",
       "      <td id=\"T_c4ece_row10_col8\" class=\"data row10 col8\" >0.922421</td>\n",
       "      <td id=\"T_c4ece_row10_col9\" class=\"data row10 col9\" >0.917415</td>\n",
       "      <td id=\"T_c4ece_row10_col10\" class=\"data row10 col10\" >0.998011</td>\n",
       "      <td id=\"T_c4ece_row10_col11\" class=\"data row10 col11\" >0.996924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row11\" class=\"row_heading level0 row11\" >6</th>\n",
       "      <td id=\"T_c4ece_row11_col0\" class=\"data row11 col0\" >Random forest</td>\n",
       "      <td id=\"T_c4ece_row11_col1\" class=\"data row11 col1\" >0.887797</td>\n",
       "      <td id=\"T_c4ece_row11_col2\" class=\"data row11 col2\" >0.999988</td>\n",
       "      <td id=\"T_c4ece_row11_col3\" class=\"data row11 col3\" >0.990760</td>\n",
       "      <td id=\"T_c4ece_row11_col4\" class=\"data row11 col4\" >0.999804</td>\n",
       "      <td id=\"T_c4ece_row11_col5\" class=\"data row11 col5\" >0.884706</td>\n",
       "      <td id=\"T_c4ece_row11_col6\" class=\"data row11 col6\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row11_col7\" class=\"data row11 col7\" >0.966581</td>\n",
       "      <td id=\"T_c4ece_row11_col8\" class=\"data row11 col8\" >0.999902</td>\n",
       "      <td id=\"T_c4ece_row11_col9\" class=\"data row11 col9\" >0.923833</td>\n",
       "      <td id=\"T_c4ece_row11_col10\" class=\"data row11 col10\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row11_col11\" class=\"data row11 col11\" >0.994786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row12\" class=\"row_heading level0 row12\" >5</th>\n",
       "      <td id=\"T_c4ece_row12_col0\" class=\"data row12 col0\" >Bagging</td>\n",
       "      <td id=\"T_c4ece_row12_col1\" class=\"data row12 col1\" >0.888780</td>\n",
       "      <td id=\"T_c4ece_row12_col2\" class=\"data row12 col2\" >0.999044</td>\n",
       "      <td id=\"T_c4ece_row12_col3\" class=\"data row12 col3\" >0.989382</td>\n",
       "      <td id=\"T_c4ece_row12_col4\" class=\"data row12 col4\" >0.986858</td>\n",
       "      <td id=\"T_c4ece_row12_col5\" class=\"data row12 col5\" >0.881176</td>\n",
       "      <td id=\"T_c4ece_row12_col6\" class=\"data row12 col6\" >0.998016</td>\n",
       "      <td id=\"T_c4ece_row12_col7\" class=\"data row12 col7\" >0.947502</td>\n",
       "      <td id=\"T_c4ece_row12_col8\" class=\"data row12 col8\" >0.992406</td>\n",
       "      <td id=\"T_c4ece_row12_col9\" class=\"data row12 col9\" >0.913136</td>\n",
       "      <td id=\"T_c4ece_row12_col10\" class=\"data row12 col10\" >0.999990</td>\n",
       "      <td id=\"T_c4ece_row12_col11\" class=\"data row12 col11\" >0.983456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row13\" class=\"row_heading level0 row13\" >10</th>\n",
       "      <td id=\"T_c4ece_row13_col0\" class=\"data row13 col0\" >DecisionTreeClassifier</td>\n",
       "      <td id=\"T_c4ece_row13_col1\" class=\"data row13 col1\" >0.883877</td>\n",
       "      <td id=\"T_c4ece_row13_col2\" class=\"data row13 col2\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row13_col3\" class=\"data row13 col3\" >0.984091</td>\n",
       "      <td id=\"T_c4ece_row13_col4\" class=\"data row13 col4\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row13_col5\" class=\"data row13 col5\" >0.864706</td>\n",
       "      <td id=\"T_c4ece_row13_col6\" class=\"data row13 col6\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row13_col7\" class=\"data row13 col7\" >0.881824</td>\n",
       "      <td id=\"T_c4ece_row13_col8\" class=\"data row13 col8\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row13_col9\" class=\"data row13 col9\" >0.873181</td>\n",
       "      <td id=\"T_c4ece_row13_col10\" class=\"data row13 col10\" >1.000000</td>\n",
       "      <td id=\"T_c4ece_row13_col11\" class=\"data row13 col11\" >0.928435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row14\" class=\"row_heading level0 row14\" >1</th>\n",
       "      <td id=\"T_c4ece_row14_col0\" class=\"data row14 col0\" >QDA</td>\n",
       "      <td id=\"T_c4ece_row14_col1\" class=\"data row14 col1\" >0.825224</td>\n",
       "      <td id=\"T_c4ece_row14_col2\" class=\"data row14 col2\" >0.981123</td>\n",
       "      <td id=\"T_c4ece_row14_col3\" class=\"data row14 col3\" >0.980551</td>\n",
       "      <td id=\"T_c4ece_row14_col4\" class=\"data row14 col4\" >0.825814</td>\n",
       "      <td id=\"T_c4ece_row14_col5\" class=\"data row14 col5\" >0.815882</td>\n",
       "      <td id=\"T_c4ece_row14_col6\" class=\"data row14 col6\" >0.869475</td>\n",
       "      <td id=\"T_c4ece_row14_col7\" class=\"data row14 col7\" >0.869048</td>\n",
       "      <td id=\"T_c4ece_row14_col8\" class=\"data row14 col8\" >0.847082</td>\n",
       "      <td id=\"T_c4ece_row14_col9\" class=\"data row14 col9\" >0.841626</td>\n",
       "      <td id=\"T_c4ece_row14_col10\" class=\"data row14 col10\" >0.989587</td>\n",
       "      <td id=\"T_c4ece_row14_col11\" class=\"data row14 col11\" >0.988034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row15\" class=\"row_heading level0 row15\" >0</th>\n",
       "      <td id=\"T_c4ece_row15_col0\" class=\"data row15 col0\" >LDA</td>\n",
       "      <td id=\"T_c4ece_row15_col1\" class=\"data row15 col1\" >0.705176</td>\n",
       "      <td id=\"T_c4ece_row15_col2\" class=\"data row15 col2\" >0.975571</td>\n",
       "      <td id=\"T_c4ece_row15_col3\" class=\"data row15 col3\" >0.976490</td>\n",
       "      <td id=\"T_c4ece_row15_col4\" class=\"data row15 col4\" >0.705963</td>\n",
       "      <td id=\"T_c4ece_row15_col5\" class=\"data row15 col5\" >0.714706</td>\n",
       "      <td id=\"T_c4ece_row15_col6\" class=\"data row15 col6\" >0.884927</td>\n",
       "      <td id=\"T_c4ece_row15_col7\" class=\"data row15 col7\" >0.892726</td>\n",
       "      <td id=\"T_c4ece_row15_col8\" class=\"data row15 col8\" >0.785379</td>\n",
       "      <td id=\"T_c4ece_row15_col9\" class=\"data row15 col9\" >0.793858</td>\n",
       "      <td id=\"T_c4ece_row15_col10\" class=\"data row15 col10\" >0.986170</td>\n",
       "      <td id=\"T_c4ece_row15_col11\" class=\"data row15 col11\" >0.985440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row16\" class=\"row_heading level0 row16\" >3</th>\n",
       "      <td id=\"T_c4ece_row16_col0\" class=\"data row16 col0\" >NB</td>\n",
       "      <td id=\"T_c4ece_row16_col1\" class=\"data row16 col1\" >0.494120</td>\n",
       "      <td id=\"T_c4ece_row16_col2\" class=\"data row16 col2\" >0.957650</td>\n",
       "      <td id=\"T_c4ece_row16_col3\" class=\"data row16 col3\" >0.958458</td>\n",
       "      <td id=\"T_c4ece_row16_col4\" class=\"data row16 col4\" >0.492938</td>\n",
       "      <td id=\"T_c4ece_row16_col5\" class=\"data row16 col5\" >0.512941</td>\n",
       "      <td id=\"T_c4ece_row16_col6\" class=\"data row16 col6\" >0.752846</td>\n",
       "      <td id=\"T_c4ece_row16_col7\" class=\"data row16 col7\" >0.752373</td>\n",
       "      <td id=\"T_c4ece_row16_col8\" class=\"data row16 col8\" >0.595780</td>\n",
       "      <td id=\"T_c4ece_row16_col9\" class=\"data row16 col9\" >0.610003</td>\n",
       "      <td id=\"T_c4ece_row16_col10\" class=\"data row16 col10\" >0.895781</td>\n",
       "      <td id=\"T_c4ece_row16_col11\" class=\"data row16 col11\" >0.888420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row17\" class=\"row_heading level0 row17\" >4</th>\n",
       "      <td id=\"T_c4ece_row17_col0\" class=\"data row17 col0\" >KNN</td>\n",
       "      <td id=\"T_c4ece_row17_col1\" class=\"data row17 col1\" >0.486667</td>\n",
       "      <td id=\"T_c4ece_row17_col2\" class=\"data row17 col2\" >0.969250</td>\n",
       "      <td id=\"T_c4ece_row17_col3\" class=\"data row17 col3\" >0.959799</td>\n",
       "      <td id=\"T_c4ece_row17_col4\" class=\"data row17 col4\" >0.630051</td>\n",
       "      <td id=\"T_c4ece_row17_col5\" class=\"data row17 col5\" >0.507647</td>\n",
       "      <td id=\"T_c4ece_row17_col6\" class=\"data row17 col6\" >0.844819</td>\n",
       "      <td id=\"T_c4ece_row17_col7\" class=\"data row17 col7\" >0.780995</td>\n",
       "      <td id=\"T_c4ece_row17_col8\" class=\"data row17 col8\" >0.721798</td>\n",
       "      <td id=\"T_c4ece_row17_col9\" class=\"data row17 col9\" >0.615330</td>\n",
       "      <td id=\"T_c4ece_row17_col10\" class=\"data row17 col10\" >0.989907</td>\n",
       "      <td id=\"T_c4ece_row17_col11\" class=\"data row17 col11\" >0.887359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4ece_level0_row18\" class=\"row_heading level0 row18\" >2</th>\n",
       "      <td id=\"T_c4ece_row18_col0\" class=\"data row18 col0\" >LR</td>\n",
       "      <td id=\"T_c4ece_row18_col1\" class=\"data row18 col1\" >0.466267</td>\n",
       "      <td id=\"T_c4ece_row18_col2\" class=\"data row18 col2\" >0.960532</td>\n",
       "      <td id=\"T_c4ece_row18_col3\" class=\"data row18 col3\" >0.961736</td>\n",
       "      <td id=\"T_c4ece_row18_col4\" class=\"data row18 col4\" >0.458219</td>\n",
       "      <td id=\"T_c4ece_row18_col5\" class=\"data row18 col5\" >0.474118</td>\n",
       "      <td id=\"T_c4ece_row18_col6\" class=\"data row18 col6\" >0.848837</td>\n",
       "      <td id=\"T_c4ece_row18_col7\" class=\"data row18 col7\" >0.858360</td>\n",
       "      <td id=\"T_c4ece_row18_col8\" class=\"data row18 col8\" >0.595159</td>\n",
       "      <td id=\"T_c4ece_row18_col9\" class=\"data row18 col9\" >0.610837</td>\n",
       "      <td id=\"T_c4ece_row18_col10\" class=\"data row18 col10\" >0.891261</td>\n",
       "      <td id=\"T_c4ece_row18_col11\" class=\"data row18 col11\" >0.884036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0c4fa5b400>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Comparing Models\n",
    "comparison_frame = pd.DataFrame(\n",
    "      {\n",
    "          \"Model\": model_names,\n",
    "          \"Cross_Val_Score_Train\": cross_val_train,\n",
    "          \"Train_Accuracy\": acc_train,\n",
    "          \"Test_Accuracy\": acc_test,\n",
    "          \"Train_Recall\": recall_train,\n",
    "          \"Test_Recall\": recall_test,\n",
    "          \"Train_Precision\": precision_train,\n",
    "          \"Test_Precision\": precision_test,\n",
    "          \"Train_F1\": f1_train,\n",
    "          \"Test_F1\": f1_test,\n",
    "          \"Train_ROC_AUC\": roc_auc_train,\n",
    "          \"Test_ROC_AUC\": roc_auc_test,\n",
    "      }\n",
    "  )\n",
    "\n",
    "  # Sorting models in decreasing order of test recall\n",
    "comparison_frame.sort_values(\n",
    "      by=[\"Test_Recall\", \"Cross_Val_Score_Train\"], ascending=False\n",
    "  ).style.highlight_max(color=\"green\", axis=0).highlight_min(color=\"red\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature3',\n",
       " 'feature5',\n",
       " 'feature6',\n",
       " 'feature8',\n",
       " 'feature9',\n",
       " 'feature10',\n",
       " 'feature16']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = X_train_over.columns[sfm_selector.get_support()].to_list()\n",
    "cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection features with SelectKBest\n",
    "\n",
    "Univariate Feature Selection is a feature selection method based on the univariate statistical test, e,g: chi2, Pearson-correlation, and many more.\n",
    "\n",
    "The premise with SelectKBest is combining the univariate statistical test with selecting the K-number of features based on the statistical result between the X and y.\n",
    "\n",
    "These objects take as input a scoring function that returns univariate scores and p-values (or only scores for SelectKBest and SelectPercentile)\n",
    "\n",
    "For classification: chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set  :  0.9495903052159848\n",
      "Accuracy on test set      :  0.9504098360655737\n",
      "Recall on training set    :  0.9481451035506882\n",
      "Recall on test set        :  0.9217647058823529\n",
      "Precision on training set :  0.9508935694909845\n",
      "Precision on test set     :  0.5667269439421339\n",
      "F1 on training set        :  0.9495173476026715\n",
      "F1 on test set            :  0.7019036954087347\n",
      "ROC-AUC Score on training set :  0.9889219982797774\n",
      "ROC-AUC Score on test set :  0.983579694885114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['feature3', 'feature15']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection  import SelectKBest\n",
    "from sklearn.feature_selection import  mutual_info_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "def select_features():\n",
    "    return SelectFromModel(estimator= XGBClassifier(random_state=seed, eval_metric=loss_func))\n",
    "\n",
    "sfm_selector = select_features()\n",
    "sfm_selector.fit(X_train_over, y_train_over)\n",
    "cols = X_train_over.columns[sfm_selector.get_support()].to_list()\n",
    "\n",
    "md = LogisticRegression()\n",
    "md.fit(X_train_over.loc[: , cols], y_train_over)\n",
    "md_metrics_score = get_metrics_score(\n",
    "          md, X_train_over.loc[:, cols], X_val.loc[:, cols], y_train_over, y_val, flag=True\n",
    "      )\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection  import SelectKBest\n",
    "from sklearn.feature_extraction import f_classif\n",
    "\n",
    "def select_features():\n",
    "    return SelectKBest(f_classif, k=2)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  X_train_sel, y_train_sel = oversampling_data().fit_resample(X_train_over, y_train_over)\n",
    "  models_sel = []\n",
    "\n",
    "  # Appending models into the list\n",
    "\n",
    "  models_sel.append((\"Bagging UpSampling + FeatureSel\", BaggingClassifier(random_state=seed)))\n",
    "  models_sel.append(\n",
    "      (\"Random forest UpSampling + FeatureSel\", RandomForestClassifier(random_state=seed))\n",
    "  )\n",
    "  models_over.append((\"GBM UpSampling + FeatureSel\", GradientBoostingClassifier(random_state=seed)))\n",
    "  models_over.append((\"Adaboost UpSampling + FeatureSel\", AdaBoostClassifier(random_state=seed)))\n",
    "  models_over.append(\n",
    "      (\"Xgboost UpSampling + FeatureSel\", XGBClassifier(random_state=seed, eval_metric=loss_func))\n",
    "  )\n",
    "  models_over.append((\"dtree UpSampling + FeatureSel\", DecisionTreeClassifier(random_state=seed)))\n",
    "  models_over.append((\"Light GBM UpSampling + FeatureSel\", lgb.LGBMClassifier(random_state=seed)))\n",
    "\n",
    "  for name, model in models_over:\n",
    "      print(name, \" model\")\n",
    "      scoring = \"recall\"\n",
    "      kfold = StratifiedKFold(\n",
    "          n_splits=10, shuffle=True, random_state=1\n",
    "      )  # Setting number of splits equal to 10\n",
    "\n",
    "      cv_result_over = cross_val_score(\n",
    "          estimator=model, X=X_train_over, y=y_train_over, scoring=scoring, cv=kfold\n",
    "      )\n",
    "      cv_results.append(cv_result_over)\n",
    "\n",
    "      model.fit(X_train_over, y_train_over)\n",
    "      model_score_over = get_metrics_score(\n",
    "          model, X_train_over, X_val, y_train_over, y_val\n",
    "      )\n",
    "      add_score_model(name, model_score_over, cv_result_over.mean())\n",
    "\n",
    "  print(\"Operation Completed!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling train data using Random Under Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Under Sampling, counts of label 'Yes': 5098\n",
      "Before Under Sampling, counts of label 'No': 75422 \n",
      "\n",
      "After Under Sampling, counts of label 'Yes': 5098\n",
      "After Under Sampling, counts of label 'No': 5098 \n",
      "\n",
      "After Under Sampling, the shape of train_X: (10196, 14)\n",
      "After Under Sampling, the shape of train_y: (10196,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def undersampling_data():\n",
    "  rus = RandomUnderSampler(random_state=1)\n",
    "  return rus\n",
    "\n",
    "\n",
    "X_train_un, y_train_un = undersampling_data().fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before Under Sampling, counts of label 'Yes': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before Under Sampling, counts of label 'No': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "print(\"After Under Sampling, counts of label 'Yes': {}\".format(sum(y_train_un == 1)))\n",
    "print(\"After Under Sampling, counts of label 'No': {} \\n\".format(sum(y_train_un == 0)))\n",
    "\n",
    "print(\"After Under Sampling, the shape of train_X: {}\".format(X_train_un.shape))\n",
    "print(\"After Under Sampling, the shape of train_y: {} \\n\".format(y_train_un.shape))\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%file undersample_model.py\n",
    "# import model\n",
    "# from model import comparison_frame, make_boxplot, add_score_model\n",
    "def undersampling_data():\n",
    "  rus = RandomUnderSampler(random_state=1)\n",
    "  return rus\n",
    "\n",
    "### STEP 3: model build and performance comparision with undersampling data: \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  X_train_un, y_train_un = undersampling_data().fit_resample(X_train, y_train)\n",
    "  models_under = []\n",
    "\n",
    "  # Appending models into the list\n",
    "\n",
    "  models_under.append((\"Bagging DownSampling\", BaggingClassifier(random_state=seed)))\n",
    "  models_under.append(\n",
    "      (\"Random forest DownSampling\", RandomForestClassifier(random_state=seed))\n",
    "  )\n",
    "  models_under.append((\"GBM DownSampling\", GradientBoostingClassifier(random_state=seed)))\n",
    "  models_under.append((\"Adaboost DownSampling\", AdaBoostClassifier(random_state=seed)))\n",
    "  models_under.append(\n",
    "      (\"Xgboost DownSampling\", XGBClassifier(random_state=seed, eval_metric=loss_func))\n",
    "  )\n",
    "  models_under.append((\"dtree DownSampling\", DecisionTreeClassifier(random_state=seed)))\n",
    "  models_under.append((\"Light GBM DownSampling\", lgb.LGBMClassifier(random_state=seed)))\n",
    "\n",
    "  for name, model in models_under:\n",
    "      scoring = \"recall\"\n",
    "      kfold = StratifiedKFold(\n",
    "          n_splits=10, shuffle=True, random_state=1\n",
    "      )  # Setting number of splits equal to 10\n",
    "\n",
    "      cv_result_under = cross_val_score(\n",
    "          estimator=model, X=X_train_un, y=y_train_un, scoring=scoring, cv=kfold\n",
    "      )\n",
    "      cv_results.append(cv_result_under)\n",
    "\n",
    "      model.fit(X_train_un, y_train_un)\n",
    "      model_score_under = get_metrics_score(model, X_train_un, X_val, y_train_un, y_val)\n",
    "      add_score_model(name, model_score_under, cv_result_under.mean())\n",
    "\n",
    "  print(\"Operation Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
